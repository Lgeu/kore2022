{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T17:29:36.871768Z",
     "iopub.status.busy": "2022-06-26T17:29:36.870797Z",
     "iopub.status.idle": "2022-06-26T17:29:36.898201Z",
     "shell.execute_reply": "2022-06-26T17:29:36.897438Z",
     "shell.execute_reply.started": "2022-06-26T17:29:36.87167Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "KAGGLE = \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
    "if KAGGLE:\n",
    "    #!pip install kaggle-environments -U\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T17:29:54.83308Z",
     "iopub.status.busy": "2022-06-26T17:29:54.832273Z",
     "iopub.status.idle": "2022-06-26T17:29:57.085244Z",
     "shell.execute_reply": "2022-06-26T17:29:57.083956Z",
     "shell.execute_reply.started": "2022-06-26T17:29:54.833044Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 30 13:09:24 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.46       Driver Version: 495.46       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   76C    P0    34W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           14Gi       480Mi        13Gi       0.0Ki       580Mi        13Gi\n",
      "Swap:            0B          0B          0B\n",
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Byte Order:                      Little Endian\n",
      "Address sizes:                   46 bits physical, 48 bits virtual\n",
      "CPU(s):                          16\n",
      "On-line CPU(s) list:             0-15\n",
      "Thread(s) per core:              2\n",
      "Core(s) per socket:              8\n",
      "Socket(s):                       1\n",
      "NUMA node(s):                    1\n",
      "Vendor ID:                       GenuineIntel\n",
      "CPU family:                      6\n",
      "Model:                           79\n",
      "Model name:                      Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "Stepping:                        0\n",
      "CPU MHz:                         2199.998\n",
      "BogoMIPS:                        4399.99\n",
      "Hypervisor vendor:               KVM\n",
      "Virtualization type:             full\n",
      "L1d cache:                       256 KiB\n",
      "L1i cache:                       256 KiB\n",
      "L2 cache:                        2 MiB\n",
      "L3 cache:                        55 MiB\n",
      "NUMA node0 CPU(s):               0-15\n",
      "Vulnerability Itlb multihit:     Not affected\n",
      "Vulnerability L1tf:              Mitigation; PTE Inversion\n",
      "Vulnerability Mds:               Mitigation; Clear CPU buffers; SMT Host state u\n",
      "                                 nknown\n",
      "Vulnerability Meltdown:          Mitigation; PTI\n",
      "Vulnerability Mmio stale data:   Vulnerable: Clear CPU buffers attempted, no mic\n",
      "                                 rocode; SMT Host state unknown\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled v\n",
      "                                 ia prctl and seccomp\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user\n",
      "                                  pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Retpolines, IBPB conditional, IBRS_\n",
      "                                 FW, STIBP conditional, RSB filling\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Mitigation; Clear CPU buffers; SMT Host state u\n",
      "                                 nknown\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtr\n",
      "                                 r pge mca cmov pat pse36 clflush mmx fxsr sse s\n",
      "                                 se2 ss ht syscall nx pdpe1gb rdtscp lm constant\n",
      "                                 _tsc rep_good nopl xtopology nonstop_tsc cpuid \n",
      "                                 tsc_known_freq pni pclmulqdq ssse3 fma cx16 pci\n",
      "                                 d sse4_1 sse4_2 x2apic movbe popcnt aes xsave a\n",
      "                                 vx f16c rdrand hypervisor lahf_lm abm 3dnowpref\n",
      "                                 etch invpcid_single pti ssbd ibrs ibpb stibp fs\n",
      "                                 gsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms \n",
      "                                 invpcid rtm rdseed adx smap xsaveopt arat md_cl\n",
      "                                 ear arch_capabilities\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!free -h\n",
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-26T17:32:30.371722Z",
     "iopub.status.busy": "2022-06-26T17:32:30.371241Z",
     "iopub.status.idle": "2022-06-26T17:32:31.603684Z",
     "shell.execute_reply": "2022-06-26T17:32:31.602291Z",
     "shell.execute_reply.started": "2022-06-26T17:32:30.371681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=cuda\n",
      "n_cpu=16\n",
      "len(kif_filenames)=47000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from time import time, sleep\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from itertools import count\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Envirionment\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device={device}\")\n",
    "\n",
    "n_cpu = !lscpu | grep ^CPU\\(s\\):\n",
    "n_cpu = int(n_cpu[0].split()[-1])\n",
    "print(f\"n_cpu={n_cpu}\")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Directory settings\n",
    "\n",
    "if KAGGLE:\n",
    "    TEMP_DIR = Path(\"../temp\")\n",
    "    STORAGE_DIR = Path()\n",
    "    PROJECTS_DIR = Path()\n",
    "else:\n",
    "    TEMP_DIR = STORAGE_DIR = Path(\"./010\")\n",
    "    PROJECTS_DIR = Path(\"../../\")\n",
    "\n",
    "if not TEMP_DIR.exists():\n",
    "    print(f\"mkdir {TEMP_DIR}\")\n",
    "    TEMP_DIR.mkdir()\n",
    "if not STORAGE_DIR.exists():\n",
    "    print(f\"mkdir {STORAGE_DIR}\")\n",
    "    STORAGE_DIR.mkdir()\n",
    "\n",
    "sys.path.append(str(STORAGE_DIR))\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "h = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"batch_size\": 32,\n",
    "    \"checkpoint_file\": \"010/latest.pt\"\n",
    "}\n",
    "\n",
    "#kif_dir = Path(\"../data/kifs/001b\")\n",
    "kif_dirs = [\n",
    "    \"../data/kifs/b-e/kifs\",\n",
    "    \"../data/kifs/f-i/kifs\",\n",
    "    \"../data/kifs/j-m/kifs\",\n",
    "    \"../data/kifs/n-q/kifs\",\n",
    "]\n",
    "kif_dirs = [Path(kif_dir) for kif_dir in kif_dirs]\n",
    "kif_filenames = sorted([str(file) for kif_dir in kif_dirs for file in kif_dir.iterdir() if file.suffix == \".kif\"])[:47000]\n",
    "print(f\"len(kif_filenames)={len(kif_filenames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T17:33:29.03675Z",
     "iopub.status.busy": "2022-06-26T17:33:29.036066Z",
     "iopub.status.idle": "2022-06-26T17:33:34.023273Z",
     "shell.execute_reply": "2022-06-26T17:33:34.02186Z",
     "shell.execute_reply.started": "2022-06-26T17:33:29.036703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "if KAGGLE:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    PERSONAL_ACCESS_TOKEN = UserSecretsClient().get_secret(\"PERSONAL_ACCESS_TOKEN\")\n",
    "\n",
    "    !git clone https://github.com/Lgeu/marathon.git\n",
    "    !rm -rf ./marathon/.git\n",
    "    !git clone https://Lgeu:{PERSONAL_ACCESS_TOKEN}@github.com/Lgeu/kore2022.git\n",
    "    !rm -rf ./kore2022/.git\n",
    "else:\n",
    "    !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T17:33:52.489702Z",
     "iopub.status.busy": "2022-06-26T17:33:52.489195Z",
     "iopub.status.idle": "2022-06-26T17:36:20.631069Z",
     "shell.execute_reply": "2022-06-26T17:36:20.630154Z",
     "shell.execute_reply.started": "2022-06-26T17:33:52.489655Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if KAGGLE:\n",
    "    # install boost\n",
    "    %cd {TEMP_DIR}\n",
    "    !wget https://boostorg.jfrog.io/artifactory/main/release/1.79.0/source/boost_1_79_0.tar.gz\n",
    "    !tar xzf boost_1_79_0.tar.gz\n",
    "    %cd -\n",
    "    %cd {TEMP_DIR / \"boost_1_79_0\"}\n",
    "    !./bootstrap.sh\n",
    "    !./b2 install -j4 --with-python -d0 cxxflags=-O3 cxxflags=-fPIC cflags=-O3 cflags=-fPIC\n",
    "    %cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!find / -name *python3.* 2> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T17:36:20.633477Z",
     "iopub.status.busy": "2022-06-26T17:36:20.632682Z",
     "iopub.status.idle": "2022-06-26T17:36:32.915401Z",
     "shell.execute_reply": "2022-06-26T17:36:32.914135Z",
     "shell.execute_reply.started": "2022-06-26T17:36:20.633434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file included from \u001b[01m\u001b[K../../kore2022/kore_fleets.cpp:1074\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K../../kore2022/kore_extension.cpp:6\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K../../kore2022/../marathon/nn.cpp:37:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"NDEBUG マクロが定義されてないよ！動作が遅くなるかもしれないよ！\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      "   37 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"NDEBUG マクロが定義されてないよ！動作が遅くなるかもしれないよ！\"\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K../../kore2022/kore_fleets.cpp:1074\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K../../kore2022/kore_extension.cpp:6\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K../../kore2022/../marathon/nn.cpp:1041:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
      " 1041 | #pragma omp parallel for\n",
      "      | \n",
      "In file included from \u001b[01m\u001b[K../../kore2022/kore_extension.cpp:6\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K../../kore2022/kore_fleets.cpp:106:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KPoint GetColRow(int)\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
      "  106 | static Point \u001b[01;35m\u001b[KGetColRow\u001b[m\u001b[K(const int pos) {\n",
      "      |              \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n"
     ]
    }
   ],
   "source": [
    "!g++ {PROJECTS_DIR / \"kore2022/kore_extension.cpp\"} -o {STORAGE_DIR / \"kore_extension.so\"} -std=c++17 -Wall -Wextra -O3 -march=haswell --shared -fPIC -I/home/user/anaconda3/include/python3.9 /usr/local/lib/libboost_numpy39.a /usr/local/lib/libboost_python39.a -lpython3.9 -L/home/user/anaconda3/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kore_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10000, 30000):\n",
    "#     print(i)\n",
    "#     kif_filename = kif_filenames[i]\n",
    "#     shipyard_features, global_features, target_values, target_action_types, \\\n",
    "#         target_action_n_ships, target_action_relative_position, target_action_n_steps, \\\n",
    "#         target_action_direction, target_action_quantized_n_ships = kore_extension.make_nnue_feature(kif_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T17:39:36.905094Z",
     "iopub.status.busy": "2022-06-26T17:39:36.90448Z",
     "iopub.status.idle": "2022-06-26T17:39:36.918126Z",
     "shell.execute_reply": "2022-06-26T17:39:36.916985Z",
     "shell.execute_reply.started": "2022-06-26T17:39:36.905051Z"
    }
   },
   "outputs": [],
   "source": [
    "#!ls -1 012 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T18:04:46.022869Z",
     "iopub.status.busy": "2022-06-26T18:04:46.022294Z",
     "iopub.status.idle": "2022-06-26T18:04:46.041421Z",
     "shell.execute_reply": "2022-06-26T18:04:46.039938Z",
     "shell.execute_reply.started": "2022-06-26T18:04:46.022807Z"
    }
   },
   "outputs": [],
   "source": [
    "class NNUEDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, kif_filenames):\n",
    "        self.kif_filenames = kif_filenames\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.kif_filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        kif_filename = self.kif_filenames[index]\n",
    "#         shipyard_features, global_features, target_values, target_action_types, \\\n",
    "#             _, target_action_relative_position, target_action_n_steps, \\\n",
    "#             target_action_direction, target_action_quantized_n_ships = kore_extension.make_nnue_feature(kif_filename)\n",
    "\n",
    "        kif_id = Path(kif_filename).stem\n",
    "        z = np.load(STORAGE_DIR.parent / f\"012/feature_{kif_id}.npz\")\n",
    "        shipyard_features, global_features, target_values, target_action_types, \\\n",
    "            target_action_n_ships, target_action_relative_position, target_action_n_steps, \\\n",
    "            target_action_direction, target_action_quantized_n_ships = (z[f] for f in z.files)\n",
    "        \n",
    "        return (\n",
    "            torch.from_numpy(shipyard_features),\n",
    "            torch.from_numpy(global_features),\n",
    "            torch.from_numpy(target_values.astype(np.float32)),\n",
    "            torch.from_numpy(target_action_types.astype(np.int64)),\n",
    "            torch.from_numpy(target_action_quantized_n_ships.astype(np.int64)),\n",
    "            torch.from_numpy(target_action_relative_position.astype(np.int64)),\n",
    "            torch.from_numpy(target_action_n_steps.astype(np.int64)),\n",
    "            torch.from_numpy(target_action_direction.astype(np.int64)),\n",
    "        )\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(torch.cat(d) for d in zip(*batch))\n",
    "\n",
    "train_dataset = NNUEDataset(kif_filenames)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=h[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=min(n_cpu, 8),\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T18:07:42.604469Z",
     "iopub.status.busy": "2022-06-26T18:07:42.603945Z",
     "iopub.status.idle": "2022-06-26T18:07:42.72477Z",
     "shell.execute_reply": "2022-06-26T18:07:42.723719Z",
     "shell.execute_reply.started": "2022-06-26T18:07:42.6044Z"
    }
   },
   "outputs": [],
   "source": [
    "N_GLOBAL_FEATURES = 9\n",
    "N_SHIPYARD_FEATURES = 32800\n",
    "\n",
    "class NNUE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.global_feature_encoder = nn.Linear(N_GLOBAL_FEATURES, 256)\n",
    "        self.embedding = nn.EmbeddingBag(N_SHIPYARD_FEATURES + 1, 256, mode=\"sum\", padding_idx=N_SHIPYARD_FEATURES)\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.value_decoder = nn.Linear(256, 1)\n",
    "        self.type_decoder = nn.Linear(256, 4)\n",
    "        self.n_ships_decoder = nn.ModuleList([\n",
    "            nn.Linear(256, 12),  # [1, 10]\n",
    "            nn.Linear(256, 32),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.Linear(256, 32),\n",
    "        ])\n",
    "        self.relative_position_decoder = nn.ModuleList([\n",
    "            None,\n",
    "            nn.Linear(256, 448),  # [0, 441)\n",
    "            nn.Linear(256, 448),\n",
    "            nn.Linear(256, 448),\n",
    "        ])\n",
    "        self.n_steps_decoder = nn.ModuleList([\n",
    "            None,\n",
    "            nn.Linear(256, 24),  # [1, 21]\n",
    "            None,\n",
    "            None,\n",
    "        ])\n",
    "        self.direction_decoder = nn.ModuleList([\n",
    "            None,\n",
    "            None,\n",
    "            nn.Linear(256, 4),\n",
    "            nn.Linear(256, 4),\n",
    "        ])\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        shipyard_features,\n",
    "        global_features,\n",
    "        target_values,\n",
    "        target_action_types,\n",
    "        target_action_n_ships,  # quantized\n",
    "        target_action_relative_position,\n",
    "        target_action_n_steps,\n",
    "        target_action_direction,\n",
    "    ):\n",
    "        batch_size = shipyard_features.size(0)\n",
    "        shipyard_features[shipyard_features == -100] = N_SHIPYARD_FEATURES\n",
    "        \n",
    "        # [batch_size, N_GLOBAL_FEATURES], [batch_size, 512] -> [batch_size, 256]\n",
    "        x = self.global_feature_encoder(global_features) + self.embedding(shipyard_features)\n",
    "        x = F.leaky_relu(x, 1.0 / 64.0)\n",
    "        \n",
    "        # [batch_size, 256]\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x, 1.0 / 64.0)\n",
    "        x = self.fc2(x)\n",
    "        x = F.leaky_relu(x, 1.0 / 64.0)\n",
    "        \n",
    "        # [batch_size, 256] -> [batch_size]\n",
    "        value = self.value_decoder(x).squeeze(1)\n",
    "        # [batch_size, 256] -> [batch_size, 4]\n",
    "        action_type = self.type_decoder(x)\n",
    "        \n",
    "        specific_predictions = []\n",
    "        for i in range(4):\n",
    "            # [batch_size, 256] -> [n_action_data, 256]\n",
    "            xi = x[target_action_types == i]\n",
    "            n_action_data = len(xi)\n",
    "#             if n_action_data == 0:\n",
    "#                 specific_predictions.append([\n",
    "#                     0, None, None, None, None\n",
    "#                 ])\n",
    "            # [n_action_data, 256] -> [n_action_data, ??]\n",
    "            n_ships = self.n_ships_decoder[i](xi)\n",
    "            # [n_action_data, 256] -> [n_action_data, ??]\n",
    "            relative_position = None if self.relative_position_decoder[i] is None else self.relative_position_decoder[i](xi)\n",
    "            # [n_action_data, 256] -> [n_action_data, ??]\n",
    "            n_steps = None if self.n_steps_decoder[i] is None else self.n_steps_decoder[i](xi)\n",
    "            # [n_action_data, 256] -> [n_action_data, ??]\n",
    "            direction = None if self.direction_decoder[i] is None else self.direction_decoder[i](xi)\n",
    "            \n",
    "            specific_predictions.append([\n",
    "                n_action_data, n_ships, relative_position, n_steps, direction\n",
    "            ])\n",
    "        \n",
    "        # === loss computation ===\n",
    "        \n",
    "        value_loss = F.binary_cross_entropy_with_logits(value, target_values, reduction=\"sum\")\n",
    "        type_loss = F.cross_entropy(action_type, target_action_types, reduction=\"sum\")\n",
    "        loss = value_loss * 10.0 + type_loss\n",
    "        ACTION_LOSS_WEIGHTS = [1.0, 1.0, 5.0, 25.0]\n",
    "        \n",
    "        specific_losses = []\n",
    "        for i in range(4):\n",
    "            n_action_data, n_ships, relative_position, n_steps, direction = specific_predictions[i]\n",
    "            indices = target_action_types == i\n",
    "            \n",
    "            n_ships_loss = F.cross_entropy(n_ships, target_action_n_ships[indices], reduction=\"sum\")\n",
    "            action_loss = n_ships_loss\n",
    "            \n",
    "            if relative_position is None:\n",
    "                relative_position_loss = None\n",
    "            else:\n",
    "                relative_position_loss = F.cross_entropy(relative_position, target_action_relative_position[indices], reduction=\"sum\")\n",
    "                action_loss += relative_position_loss\n",
    "            \n",
    "            if n_steps is None:\n",
    "                n_steps_loss = None\n",
    "            else:\n",
    "                n_steps_loss = F.cross_entropy(n_steps, target_action_n_steps[indices], reduction=\"sum\")\n",
    "                action_loss += n_steps_loss\n",
    "            \n",
    "            if direction is None:\n",
    "                direction_loss = None\n",
    "            else:\n",
    "                direction_loss = F.cross_entropy(direction, target_action_direction[indices], reduction=\"sum\")\n",
    "                action_loss += direction_loss\n",
    "            \n",
    "            loss += ACTION_LOSS_WEIGHTS[i] * action_loss\n",
    "            \n",
    "            specific_losses.append([\n",
    "                n_action_data, n_ships_loss, relative_position_loss, n_steps_loss, direction_loss\n",
    "            ])\n",
    "        \n",
    "        loss *= 1 / batch_size\n",
    "        \n",
    "        return (value, action_type, specific_predictions), (value_loss, type_loss, specific_losses), loss\n",
    "\n",
    "model = NNUE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T18:18:47.52493Z",
     "iopub.status.busy": "2022-06-26T18:18:47.52435Z",
     "iopub.status.idle": "2022-06-26T18:20:14.923467Z",
     "shell.execute_reply": "2022-06-26T18:20:14.92139Z",
     "shell.execute_reply.started": "2022-06-26T18:18:47.524846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2c15745b3c4c6f99c94fc157427233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iteration = 0\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=h[\"lr\"])\n",
    "\n",
    "if h[\"checkpoint_file\"]:\n",
    "    dict_checkpoint = torch.load(h[\"checkpoint_file\"], map_location=\"cpu\")\n",
    "    model.load_state_dict(dict_checkpoint[\"state_dict\"], strict=False)\n",
    "    if True:#not h[\"finetuning\"]:\n",
    "        optimizer.load_state_dict(dict_checkpoint[\"optimizer\"])\n",
    "        iteration = dict_checkpoint[\"iteration\"]\n",
    "        for name, value in dict_checkpoint.items():\n",
    "            if isinstance(value, int):\n",
    "                globals()[\"name\"] = value\n",
    "    del dict_checkpoint\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "train_loader_iter = iter(train_loader)\n",
    "training_stats = defaultdict(lambda: [0, 0.0])\n",
    "ACTION_NAMES = [\"spawn\", \"move\", \"attack\", \"convert\"]\n",
    "if not KAGGLE:\n",
    "    writer = SummaryWriter(STORAGE_DIR)\n",
    "t0 = time()\n",
    "\n",
    "def update_loss_stats(training_stats, value_loss, type_loss, specific_losses):\n",
    "    data_size = sum(specific_loss[0] for specific_loss in specific_losses)\n",
    "    training_stats[\"value_loss\"][0] += data_size\n",
    "    training_stats[\"value_loss\"][1] += value_loss.item()\n",
    "    training_stats[\"type_loss\"][0] += data_size\n",
    "    training_stats[\"type_loss\"][1] += type_loss.item()\n",
    "    for action_name, (n_action_data, n_ships_loss, relative_position_loss, n_steps_loss, direction_loss) in zip(ACTION_NAMES, specific_losses):\n",
    "        training_stats[f\"{action_name}_n_ships_loss\"][0] += n_action_data\n",
    "        training_stats[f\"{action_name}_n_ships_loss\"][1] += n_ships_loss.item()\n",
    "        if relative_position_loss is not None:\n",
    "            training_stats[f\"{action_name}_relative_position_loss\"][0] += n_action_data\n",
    "            training_stats[f\"{action_name}_relative_position_loss\"][1] += relative_position_loss.item()\n",
    "        if n_steps_loss is not None:\n",
    "            training_stats[f\"{action_name}_n_steps_loss\"][0] += n_action_data\n",
    "            training_stats[f\"{action_name}_n_steps_loss\"][1] += n_steps_loss.item()\n",
    "        if direction_loss is not None:\n",
    "            training_stats[f\"{action_name}_direction_loss\"][0] += n_action_data\n",
    "            training_stats[f\"{action_name}_direction_loss\"][1] += direction_loss.item()\n",
    "\n",
    "for iteration in tqdm(count(iteration)):\n",
    "    #print(iteration)\n",
    "    model.train()\n",
    "    \n",
    "    try:\n",
    "        batch = next(train_loader_iter)\n",
    "    except StopIteration:\n",
    "        train_loader_iter = iter(train_loader)\n",
    "        batch = next(train_loader_iter)\n",
    "    \n",
    "    batch = tuple(d.to(device) for d in batch)\n",
    "    optimizer.zero_grad()\n",
    "    (value, action_type, specific_predictions), (value_loss, type_loss, specific_losses), loss = model(*batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    update_loss_stats(training_stats, value_loss, type_loss, specific_losses)\n",
    "    \n",
    "    # dump stats\n",
    "    if (iteration + 1) % 1000 == 0 or iteration == 9:\n",
    "        with open(STORAGE_DIR / \"log.txt\", \"a\") as f:\n",
    "            t = round(time() - t0, 1)\n",
    "            json.dump({\n",
    "                \"time\": t,\n",
    "                \"iteration\": iteration,\n",
    "                \"stats\": training_stats,\n",
    "            }, f)\n",
    "            f.write(\"\\n\")\n",
    "        if not KAGGLE:\n",
    "            for name, stat in training_stats.items():\n",
    "                if stat[0] > 0:\n",
    "                    writer.add_scalar(\"loss/\" + name, stat[1] / stat[0], iteration + 1)\n",
    "        training_stats.clear()\n",
    "\n",
    "    # save model\n",
    "    if (iteration + 1) % 10000 == 0 or iteration == 9:\n",
    "        checkpoint_file = STORAGE_DIR / f\"checkpoint_{iteration + 1:08d}.pt\"\n",
    "        torch.save({\n",
    "            \"iteration\": iteration + 1,\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        }, checkpoint_file)\n",
    "        !cp {checkpoint_file} {STORAGE_DIR / \"latest.pt\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40k iter から value_loss の係数を 1 から 10 に変更\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
