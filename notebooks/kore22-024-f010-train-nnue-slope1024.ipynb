{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T17:29:36.871768Z",
     "iopub.status.busy": "2022-06-26T17:29:36.870797Z",
     "iopub.status.idle": "2022-06-26T17:29:36.898201Z",
     "shell.execute_reply": "2022-06-26T17:29:36.897438Z",
     "shell.execute_reply.started": "2022-06-26T17:29:36.87167Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "KAGGLE = \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
    "if KAGGLE:\n",
    "    #!pip install kaggle-environments -U\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T17:29:54.83308Z",
     "iopub.status.busy": "2022-06-26T17:29:54.832273Z",
     "iopub.status.idle": "2022-06-26T17:29:57.085244Z",
     "shell.execute_reply": "2022-06-26T17:29:57.083956Z",
     "shell.execute_reply.started": "2022-06-26T17:29:54.833044Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 12 12:55:40 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.46       Driver Version: 495.46       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   73C    P0    30W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           14Gi       1.8Gi       6.7Gi        44Mi       5.6Gi        11Gi\n",
      "Swap:            0B          0B          0B\n",
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Byte Order:                      Little Endian\n",
      "Address sizes:                   46 bits physical, 48 bits virtual\n",
      "CPU(s):                          16\n",
      "On-line CPU(s) list:             0-15\n",
      "Thread(s) per core:              2\n",
      "Core(s) per socket:              8\n",
      "Socket(s):                       1\n",
      "NUMA node(s):                    1\n",
      "Vendor ID:                       GenuineIntel\n",
      "CPU family:                      6\n",
      "Model:                           79\n",
      "Model name:                      Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "Stepping:                        0\n",
      "CPU MHz:                         2199.998\n",
      "BogoMIPS:                        4399.99\n",
      "Hypervisor vendor:               KVM\n",
      "Virtualization type:             full\n",
      "L1d cache:                       256 KiB\n",
      "L1i cache:                       256 KiB\n",
      "L2 cache:                        2 MiB\n",
      "L3 cache:                        55 MiB\n",
      "NUMA node0 CPU(s):               0-15\n",
      "Vulnerability Itlb multihit:     Not affected\n",
      "Vulnerability L1tf:              Mitigation; PTE Inversion\n",
      "Vulnerability Mds:               Mitigation; Clear CPU buffers; SMT Host state u\n",
      "                                 nknown\n",
      "Vulnerability Meltdown:          Mitigation; PTI\n",
      "Vulnerability Mmio stale data:   Vulnerable: Clear CPU buffers attempted, no mic\n",
      "                                 rocode; SMT Host state unknown\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled v\n",
      "                                 ia prctl and seccomp\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user\n",
      "                                  pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Retpolines, IBPB conditional, IBRS_\n",
      "                                 FW, STIBP conditional, RSB filling\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Mitigation; Clear CPU buffers; SMT Host state u\n",
      "                                 nknown\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtr\n",
      "                                 r pge mca cmov pat pse36 clflush mmx fxsr sse s\n",
      "                                 se2 ss ht syscall nx pdpe1gb rdtscp lm constant\n",
      "                                 _tsc rep_good nopl xtopology nonstop_tsc cpuid \n",
      "                                 tsc_known_freq pni pclmulqdq ssse3 fma cx16 pci\n",
      "                                 d sse4_1 sse4_2 x2apic movbe popcnt aes xsave a\n",
      "                                 vx f16c rdrand hypervisor lahf_lm abm 3dnowpref\n",
      "                                 etch invpcid_single pti ssbd ibrs ibpb stibp fs\n",
      "                                 gsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms \n",
      "                                 invpcid rtm rdseed adx smap xsaveopt arat md_cl\n",
      "                                 ear arch_capabilities\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!free -h\n",
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-26T17:32:30.371722Z",
     "iopub.status.busy": "2022-06-26T17:32:30.371241Z",
     "iopub.status.idle": "2022-06-26T17:32:31.603684Z",
     "shell.execute_reply": "2022-06-26T17:32:31.602291Z",
     "shell.execute_reply.started": "2022-06-26T17:32:30.371681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=cuda\n",
      "n_cpu=16\n",
      "len(kif_filenames)=84000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from time import time, sleep\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from itertools import count\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Envirionment\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device={device}\")\n",
    "\n",
    "n_cpu = !lscpu | grep ^CPU\\(s\\):\n",
    "n_cpu = int(n_cpu[0].split()[-1])\n",
    "print(f\"n_cpu={n_cpu}\")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Directory settings\n",
    "\n",
    "if KAGGLE:\n",
    "    TEMP_DIR = Path(\"../temp\")\n",
    "    STORAGE_DIR = Path()\n",
    "    PROJECTS_DIR = Path()\n",
    "else:\n",
    "    TEMP_DIR = STORAGE_DIR = Path(\"./024\")\n",
    "    PROJECTS_DIR = Path(\"../../\")\n",
    "\n",
    "if not TEMP_DIR.exists():\n",
    "    print(f\"mkdir {TEMP_DIR}\")\n",
    "    TEMP_DIR.mkdir()\n",
    "if not STORAGE_DIR.exists():\n",
    "    print(f\"mkdir {STORAGE_DIR}\")\n",
    "    STORAGE_DIR.mkdir()\n",
    "\n",
    "sys.path.append(str(STORAGE_DIR))\n",
    "sys.path.append(str(PROJECTS_DIR / \"kore2022\"))\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "h = {\n",
    "    \"lr\": 5e-4,\n",
    "    \"batch_size\": 32,\n",
    "    #\"checkpoint_file\": \"010/latest.pt\",\n",
    "    \"checkpoint_file\": \"024/latest.pt\",\n",
    "}\n",
    "\n",
    "#kif_dir = Path(\"../data/kifs/001b\")\n",
    "kif_dirs = [\n",
    "    \"../data/kifs/b-e/kifs\",\n",
    "    \"../data/kifs/f-i/kifs\",\n",
    "    \"../data/kifs/j-m/kifs\",\n",
    "    \"../data/kifs/n-q/kifs\",\n",
    "    \"../data/kifs/r-u/kifs\",\n",
    "    \"../data/kifs/v-y/kifs\",\n",
    "    \"../data/kifs/z-zc/kifs\",\n",
    "]\n",
    "kif_dirs = [Path(kif_dir) for kif_dir in kif_dirs]\n",
    "kif_filenames = sorted([str(file) for kif_dir in kif_dirs for file in kif_dir.iterdir() if file.suffix == \".kif\"])\n",
    "print(f\"len(kif_filenames)={len(kif_filenames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T17:33:29.03675Z",
     "iopub.status.busy": "2022-06-26T17:33:29.036066Z",
     "iopub.status.idle": "2022-06-26T17:33:34.023273Z",
     "shell.execute_reply": "2022-06-26T17:33:34.02186Z",
     "shell.execute_reply.started": "2022-06-26T17:33:29.036703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 47, done.\u001b[K\n",
      "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
      "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
      "remote: Total 44 (delta 31), reused 28 (delta 15), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (44/44), 7.26 KiB | 121.00 KiB/s, done.\n",
      "From github.com:Lgeu/kore2022\n",
      "   5b15695..dcdcd2f  master         -> origin/master\n",
      " * [new branch]      n-children-8-2 -> origin/n-children-8-2\n",
      " * [new branch]      primitive      -> origin/primitive\n",
      " * [new branch]      relu           -> origin/relu\n",
      "Updating 5b15695..dcdcd2f\n",
      "Fast-forward\n",
      " environment.cpp |   40 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
      " nnue.cpp        | 1027 \u001b[32m++++++++\u001b[m\u001b[31m-----------------------------------------------\u001b[m\n",
      " 2 files changed, 172 insertions(+), 895 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "if KAGGLE:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    PERSONAL_ACCESS_TOKEN = UserSecretsClient().get_secret(\"PERSONAL_ACCESS_TOKEN\")\n",
    "\n",
    "    !git clone https://github.com/Lgeu/marathon.git\n",
    "    !rm -rf ./marathon/.git\n",
    "    !git clone https://Lgeu:{PERSONAL_ACCESS_TOKEN}@github.com/Lgeu/kore2022.git\n",
    "    !rm -rf ./kore2022/.git\n",
    "else:\n",
    "    !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inversion import (\n",
    "    shipyard_feature_converter_f1,\n",
    "    shipyard_feature_converter_f2,\n",
    "    direction_converter_f1,\n",
    "    direction_converter_f2,\n",
    "    relative_position_converter_f1,\n",
    "    relative_position_converter_f2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T17:33:52.489702Z",
     "iopub.status.busy": "2022-06-26T17:33:52.489195Z",
     "iopub.status.idle": "2022-06-26T17:36:20.631069Z",
     "shell.execute_reply": "2022-06-26T17:36:20.630154Z",
     "shell.execute_reply.started": "2022-06-26T17:33:52.489655Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if KAGGLE:\n",
    "    # install boost\n",
    "    %cd {TEMP_DIR}\n",
    "    !wget https://boostorg.jfrog.io/artifactory/main/release/1.79.0/source/boost_1_79_0.tar.gz\n",
    "    !tar xzf boost_1_79_0.tar.gz\n",
    "    %cd -\n",
    "    %cd {TEMP_DIR / \"boost_1_79_0\"}\n",
    "    !./bootstrap.sh\n",
    "    !./b2 install -j4 --with-python -d0 cxxflags=-O3 cxxflags=-fPIC cflags=-O3 cflags=-fPIC\n",
    "    %cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!find / -name *python3.* 2> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T17:36:20.633477Z",
     "iopub.status.busy": "2022-06-26T17:36:20.632682Z",
     "iopub.status.idle": "2022-06-26T17:36:32.915401Z",
     "shell.execute_reply": "2022-06-26T17:36:32.914135Z",
     "shell.execute_reply.started": "2022-06-26T17:36:20.633434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file included from \u001b[01m\u001b[K../../kore2022/environment.cpp:1026\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K../../kore2022/kore_extension.cpp:7\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K../../kore2022/../marathon/nn.cpp:37:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"NDEBUG マクロが定義されてないよ！動作が遅くなるかもしれないよ！\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      "   37 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"NDEBUG マクロが定義されてないよ！動作が遅くなるかもしれないよ！\"\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K../../kore2022/environment.cpp:1026\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K../../kore2022/kore_extension.cpp:7\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K../../kore2022/../marathon/nn.cpp:1041:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
      " 1041 | #pragma omp parallel for\n",
      "      | \n",
      "In file included from \u001b[01m\u001b[K../../kore2022/kore_extension.cpp:7\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K../../kore2022/environment.cpp:\u001b[m\u001b[K In constructor ‘\u001b[01m\u001b[KNNUEFeature::NNUEFeature(const State&)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../../kore2022/environment.cpp:1217:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Knarrowing conversion of ‘\u001b[01m\u001b[K(int)((signed char)p.Vec2<signed char>::y)\u001b[m\u001b[K’ from ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ to ‘\u001b[01m\u001b[Ksigned char\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wnarrowing\u001b[m\u001b[K]\n",
      " 1217 |                 auto q = Point{\u001b[01;35m\u001b[K(int)p.y\u001b[m\u001b[K, p.x == 0 ? kSize - 1 : p.x - 1};\n",
      "      |                                \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../../kore2022/environment.cpp:1217:51:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Knarrowing conversion of ‘\u001b[01m\u001b[K((((int)p.Vec2<signed char>::x) == 0) ? (((int)kSize) - 1) : (((int)p.Vec2<signed char>::x) - 1))\u001b[m\u001b[K’ from ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ to ‘\u001b[01m\u001b[Ksigned char\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wnarrowing\u001b[m\u001b[K]\n",
      " 1217 |                 auto q = Point{(int)p.y, \u001b[01;35m\u001b[Kp.x == 0 ? kSize - 1 : p.x - 1\u001b[m\u001b[K};\n",
      "      |                                          \u001b[01;35m\u001b[K~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../../kore2022/environment.cpp:1223:22:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Knarrowing conversion of ‘\u001b[01m\u001b[K(int)((signed char)p.Vec2<signed char>::y)\u001b[m\u001b[K’ from ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ to ‘\u001b[01m\u001b[Ksigned char\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wnarrowing\u001b[m\u001b[K]\n",
      " 1223 |                 q = {\u001b[01;35m\u001b[K(int)p.y\u001b[m\u001b[K, p.x == kSize - 1 ? 0 : p.x + 1};\n",
      "      |                      \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../../kore2022/environment.cpp:1223:49:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Knarrowing conversion of ‘\u001b[01m\u001b[K((((int)p.Vec2<signed char>::x) == (((int)kSize) - 1)) ? 0 : (((int)p.Vec2<signed char>::x) + 1))\u001b[m\u001b[K’ from ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ to ‘\u001b[01m\u001b[Ksigned char\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wnarrowing\u001b[m\u001b[K]\n",
      " 1223 |                 q = {(int)p.y, \u001b[01;35m\u001b[Kp.x == kSize - 1 ? 0 : p.x + 1\u001b[m\u001b[K};\n",
      "      |                                \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../../kore2022/environment.cpp:1229:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Knarrowing conversion of ‘\u001b[01m\u001b[K((((int)p.Vec2<signed char>::y) == 0) ? (((int)kSize) - 1) : (((int)p.Vec2<signed char>::y) - 1))\u001b[m\u001b[K’ from ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ to ‘\u001b[01m\u001b[Ksigned char\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wnarrowing\u001b[m\u001b[K]\n",
      " 1229 |                 q = {\u001b[01;35m\u001b[Kp.y == 0 ? kSize - 1 : p.y - 1\u001b[m\u001b[K, (int)p.x};\n",
      "      |                      \u001b[01;35m\u001b[K~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../../kore2022/environment.cpp:1229:54:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Knarrowing conversion of ‘\u001b[01m\u001b[K(int)((signed char)p.Vec2<signed char>::x)\u001b[m\u001b[K’ from ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ to ‘\u001b[01m\u001b[Ksigned char\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wnarrowing\u001b[m\u001b[K]\n",
      " 1229 |                 q = {p.y == 0 ? kSize - 1 : p.y - 1, \u001b[01;35m\u001b[K(int)p.x\u001b[m\u001b[K};\n",
      "      |                                                      \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../../kore2022/environment.cpp:1235:39:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Knarrowing conversion of ‘\u001b[01m\u001b[K((((int)p.Vec2<signed char>::y) == (((int)kSize) - 1)) ? 0 : (((int)p.Vec2<signed char>::y) + 1))\u001b[m\u001b[K’ from ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ to ‘\u001b[01m\u001b[Ksigned char\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wnarrowing\u001b[m\u001b[K]\n",
      " 1235 |                 q = {\u001b[01;35m\u001b[Kp.y == kSize - 1 ? 0 : p.y + 1\u001b[m\u001b[K, (int)p.x};\n",
      "      |                      \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../../kore2022/environment.cpp:1235:54:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Knarrowing conversion of ‘\u001b[01m\u001b[K(int)((signed char)p.Vec2<signed char>::x)\u001b[m\u001b[K’ from ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ to ‘\u001b[01m\u001b[Ksigned char\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wnarrowing\u001b[m\u001b[K]\n",
      " 1235 |                 q = {p.y == kSize - 1 ? 0 : p.y + 1, \u001b[01;35m\u001b[K(int)p.x\u001b[m\u001b[K};\n",
      "      |                                                      \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n"
     ]
    }
   ],
   "source": [
    "!g++ {PROJECTS_DIR / \"kore2022/kore_extension.cpp\"} -o {STORAGE_DIR / \"kore_extension.so\"} -std=c++17 -Wall -Wextra -O3 -march=haswell --shared -fPIC -I/home/user/anaconda3/include/python3.9 /usr/local/lib/libboost_numpy39.a /usr/local/lib/libboost_python39.a -lpython3.9 -L/home/user/anaconda3/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kore_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10000, 30000):\n",
    "#     print(i)\n",
    "#     kif_filename = kif_filenames[i]\n",
    "#     shipyard_features, global_features, target_values, target_action_types, \\\n",
    "#         target_action_n_ships, target_action_relative_position, target_action_n_steps, \\\n",
    "#         target_action_direction, target_action_quantized_n_ships = kore_extension.make_nnue_feature(kif_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T17:39:36.905094Z",
     "iopub.status.busy": "2022-06-26T17:39:36.90448Z",
     "iopub.status.idle": "2022-06-26T17:39:36.918126Z",
     "shell.execute_reply": "2022-06-26T17:39:36.916985Z",
     "shell.execute_reply.started": "2022-06-26T17:39:36.905051Z"
    }
   },
   "outputs": [],
   "source": [
    "#!ls -1 012 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T18:04:46.022869Z",
     "iopub.status.busy": "2022-06-26T18:04:46.022294Z",
     "iopub.status.idle": "2022-06-26T18:04:46.041421Z",
     "shell.execute_reply": "2022-06-26T18:04:46.039938Z",
     "shell.execute_reply.started": "2022-06-26T18:04:46.022807Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    shipyard_feature_converter_f1,\n",
    "    shipyard_feature_converter_f2,\n",
    "    direction_converter_f1,\n",
    "    direction_converter_f2,\n",
    "    relative_position_converter_f1,\n",
    "    relative_position_converter_f2,\n",
    ") = map(np.array, (\n",
    "    shipyard_feature_converter_f1,\n",
    "    shipyard_feature_converter_f2,\n",
    "    direction_converter_f1,\n",
    "    direction_converter_f2,\n",
    "    relative_position_converter_f1,\n",
    "    relative_position_converter_f2,\n",
    "))\n",
    "\n",
    "class NNUEDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, kif_filenames):\n",
    "        self.kif_filenames = kif_filenames\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.kif_filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        kif_filename = self.kif_filenames[index]\n",
    "#         shipyard_features, global_features, target_values, target_action_types, \\\n",
    "#             _, target_action_relative_position, target_action_n_steps, \\\n",
    "#             target_action_direction, target_action_quantized_n_ships = kore_extension.make_nnue_feature(kif_filename)\n",
    "\n",
    "        kif_id = Path(kif_filename).stem\n",
    "        z = np.load(STORAGE_DIR.parent / f\"012/feature_{kif_id}.npz\")\n",
    "        shipyard_features, global_features, target_values, target_action_types, \\\n",
    "            target_action_n_ships, target_action_relative_position, target_action_n_steps, \\\n",
    "            target_action_direction, target_action_quantized_n_ships = (z[f] for f in z.files)\n",
    "        \n",
    "        n_data = len(shipyard_features)\n",
    "        condition_1 = torch.randint(2, (n_data,), dtype=torch.bool).numpy()\n",
    "        condition_2 = torch.randint(2, (n_data,), dtype=torch.bool).numpy()\n",
    "        shipyard_has_value = shipyard_features != -100\n",
    "        shipyard_features[condition_1[:, None] & shipyard_has_value]      = shipyard_feature_converter_f1[shipyard_features[condition_1[:, None] & shipyard_has_value]]\n",
    "        shipyard_features[condition_2[:, None] & shipyard_has_value]      = shipyard_feature_converter_f2[shipyard_features[condition_2[:, None] & shipyard_has_value]]\n",
    "        direction_has_value = target_action_direction != -100\n",
    "        target_action_direction[condition_1 & direction_has_value]        = direction_converter_f1[target_action_direction[condition_1 & direction_has_value]]\n",
    "        target_action_direction[condition_2 & direction_has_value]        = direction_converter_f2[target_action_direction[condition_2 & direction_has_value]]\n",
    "        position_has_value = target_action_relative_position != -100\n",
    "        target_action_relative_position[condition_1 & position_has_value] = relative_position_converter_f1[target_action_relative_position[condition_1 & position_has_value]]\n",
    "        target_action_relative_position[condition_2 & position_has_value] = relative_position_converter_f2[target_action_relative_position[condition_2 & position_has_value]]\n",
    "        \n",
    "        return (\n",
    "            torch.from_numpy(shipyard_features),\n",
    "            torch.from_numpy(global_features),\n",
    "            torch.from_numpy(target_values.astype(np.float32)),\n",
    "            torch.from_numpy(target_action_types.astype(np.int64)),\n",
    "            torch.from_numpy(target_action_quantized_n_ships.astype(np.int64)),\n",
    "            torch.from_numpy(target_action_relative_position.astype(np.int64)),\n",
    "            torch.from_numpy(target_action_n_steps.astype(np.int64)),\n",
    "            torch.from_numpy(target_action_direction.astype(np.int64)),\n",
    "        )\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(torch.cat(d) for d in zip(*batch))\n",
    "\n",
    "train_dataset = NNUEDataset(kif_filenames)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=h[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=min(n_cpu, 8),\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T18:07:42.604469Z",
     "iopub.status.busy": "2022-06-26T18:07:42.603945Z",
     "iopub.status.idle": "2022-06-26T18:07:42.72477Z",
     "shell.execute_reply": "2022-06-26T18:07:42.723719Z",
     "shell.execute_reply.started": "2022-06-26T18:07:42.6044Z"
    }
   },
   "outputs": [],
   "source": [
    "N_GLOBAL_FEATURES = 9\n",
    "N_SHIPYARD_FEATURES = 32800\n",
    "\n",
    "class NNUE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.global_feature_encoder = nn.Linear(N_GLOBAL_FEATURES, 256)\n",
    "        self.embedding = nn.EmbeddingBag(N_SHIPYARD_FEATURES + 1, 256, mode=\"sum\", padding_idx=N_SHIPYARD_FEATURES)\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.value_decoder = nn.Linear(256, 1)\n",
    "        self.type_decoder = nn.Linear(256, 4)\n",
    "        self.n_ships_decoder = nn.ModuleList([\n",
    "            nn.Linear(256, 12),  # [1, 10]\n",
    "            nn.Linear(256, 32),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.Linear(256, 32),\n",
    "        ])\n",
    "        self.relative_position_decoder = nn.ModuleList([\n",
    "            None,\n",
    "            nn.Linear(256, 448),  # [0, 441)\n",
    "            nn.Linear(256, 448),\n",
    "            nn.Linear(256, 448),\n",
    "        ])\n",
    "        self.n_steps_decoder = nn.ModuleList([\n",
    "            None,\n",
    "            nn.Linear(256, 24),  # [1, 21]\n",
    "            None,\n",
    "            None,\n",
    "        ])\n",
    "        self.direction_decoder = nn.ModuleList([\n",
    "            None,\n",
    "            None,\n",
    "            nn.Linear(256, 4),\n",
    "            nn.Linear(256, 4),\n",
    "        ])\n",
    "    \n",
    "    def dump(self, file):\n",
    "        # file: filname or file pointer\n",
    "        if isinstance(file, str):\n",
    "            f = open(file, \"wb\")\n",
    "        elif hasattr(file, \"write\"):\n",
    "            f = file\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        def write(params):\n",
    "            f.write(params.detach().cpu().numpy().ravel().tobytes())\n",
    "        \n",
    "        write(self.global_feature_encoder.weight)\n",
    "        write(self.global_feature_encoder.bias)\n",
    "        write(self.embedding.weight)\n",
    "        write(self.fc1.weight)\n",
    "        write(self.fc1.bias)\n",
    "        write(self.fc2.weight)\n",
    "        write(self.fc2.bias)\n",
    "        write(self.value_decoder.weight)\n",
    "        write(self.value_decoder.bias)\n",
    "        write(self.type_decoder.weight)\n",
    "        write(self.type_decoder.bias)\n",
    "        \n",
    "        # Spawn\n",
    "        write(self.n_ships_decoder[0].weight)\n",
    "        write(self.n_ships_decoder[0].bias)\n",
    "        \n",
    "        # Move\n",
    "        write(self.n_ships_decoder[1].weight)\n",
    "        write(self.n_ships_decoder[1].bias)\n",
    "        write(self.relative_position_decoder[1].weight)\n",
    "        write(self.relative_position_decoder[1].bias)\n",
    "        write(self.n_steps_decoder[1].weight)\n",
    "        write(self.n_steps_decoder[1].bias)\n",
    "        \n",
    "        # Attack\n",
    "        write(self.n_ships_decoder[2].weight)\n",
    "        write(self.n_ships_decoder[2].bias)\n",
    "        write(self.relative_position_decoder[2].weight)\n",
    "        write(self.relative_position_decoder[2].bias)\n",
    "        write(self.direction_decoder[2].weight)\n",
    "        write(self.direction_decoder[2].bias)\n",
    "        \n",
    "        # Convert\n",
    "        write(self.n_ships_decoder[3].weight)\n",
    "        write(self.n_ships_decoder[3].bias)\n",
    "        write(self.relative_position_decoder[3].weight)\n",
    "        write(self.relative_position_decoder[3].bias)\n",
    "        write(self.direction_decoder[3].weight)\n",
    "        write(self.direction_decoder[3].bias)\n",
    "        \n",
    "        \n",
    "        if isinstance(file, str):\n",
    "            f.close()\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        shipyard_features,\n",
    "        global_features,\n",
    "        target_values,\n",
    "        target_action_types,\n",
    "        target_action_n_ships,  # quantized\n",
    "        target_action_relative_position,\n",
    "        target_action_n_steps,\n",
    "        target_action_direction,\n",
    "    ):\n",
    "        batch_size = shipyard_features.size(0)\n",
    "        shipyard_features[shipyard_features == -100] = N_SHIPYARD_FEATURES\n",
    "        \n",
    "        # [batch_size, N_GLOBAL_FEATURES], [batch_size, 512] -> [batch_size, 256]\n",
    "        x = self.global_feature_encoder(global_features) + self.embedding(shipyard_features)\n",
    "        x = F.leaky_relu(x, 1.0 / 1024.0)\n",
    "        \n",
    "        # [batch_size, 256]\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x, 1.0 / 1024.0)\n",
    "        x = self.fc2(x)\n",
    "        x = F.leaky_relu(x, 1.0 / 1024.0)\n",
    "        \n",
    "        # [batch_size, 256] -> [batch_size]\n",
    "        value = self.value_decoder(x).squeeze(1)\n",
    "        # [batch_size, 256] -> [batch_size, 4]\n",
    "        action_type = self.type_decoder(x)\n",
    "        \n",
    "        specific_predictions = []\n",
    "        for i in range(4):\n",
    "            # [batch_size, 256] -> [n_action_data, 256]\n",
    "            xi = x[target_action_types == i]\n",
    "            n_action_data = len(xi)\n",
    "#             if n_action_data == 0:\n",
    "#                 specific_predictions.append([\n",
    "#                     0, None, None, None, None\n",
    "#                 ])\n",
    "            # [n_action_data, 256] -> [n_action_data, ??]\n",
    "            n_ships = self.n_ships_decoder[i](xi)\n",
    "            # [n_action_data, 256] -> [n_action_data, ??]\n",
    "            relative_position = None if self.relative_position_decoder[i] is None else self.relative_position_decoder[i](xi)\n",
    "            # [n_action_data, 256] -> [n_action_data, ??]\n",
    "            n_steps = None if self.n_steps_decoder[i] is None else self.n_steps_decoder[i](xi)\n",
    "            # [n_action_data, 256] -> [n_action_data, ??]\n",
    "            direction = None if self.direction_decoder[i] is None else self.direction_decoder[i](xi)\n",
    "            \n",
    "            specific_predictions.append([\n",
    "                n_action_data, n_ships, relative_position, n_steps, direction\n",
    "            ])\n",
    "        \n",
    "        # === loss computation ===\n",
    "        \n",
    "        value_loss = F.binary_cross_entropy_with_logits(value, target_values, reduction=\"sum\")\n",
    "        type_loss = F.cross_entropy(action_type, target_action_types, reduction=\"sum\")\n",
    "        loss = value_loss * 10.0 + type_loss\n",
    "        ACTION_LOSS_WEIGHTS = [1.0, 1.0, 5.0, 25.0]\n",
    "        \n",
    "        specific_losses = []\n",
    "        for i in range(4):\n",
    "            n_action_data, n_ships, relative_position, n_steps, direction = specific_predictions[i]\n",
    "            indices = target_action_types == i\n",
    "            \n",
    "            n_ships_loss = F.cross_entropy(n_ships, target_action_n_ships[indices], reduction=\"sum\")\n",
    "            action_loss = n_ships_loss.clone()\n",
    "            \n",
    "            if relative_position is None:\n",
    "                relative_position_loss = None\n",
    "            else:\n",
    "                relative_position_loss = F.cross_entropy(relative_position, target_action_relative_position[indices], reduction=\"sum\")\n",
    "                action_loss += relative_position_loss\n",
    "            \n",
    "            if n_steps is None:\n",
    "                n_steps_loss = None\n",
    "            else:\n",
    "                n_steps_loss = F.cross_entropy(n_steps, target_action_n_steps[indices], reduction=\"sum\")\n",
    "                action_loss += n_steps_loss\n",
    "            \n",
    "            if direction is None:\n",
    "                direction_loss = None\n",
    "            else:\n",
    "                direction_loss = F.cross_entropy(direction, target_action_direction[indices], reduction=\"sum\")\n",
    "                action_loss += direction_loss\n",
    "            \n",
    "            loss += ACTION_LOSS_WEIGHTS[i] * action_loss\n",
    "            \n",
    "            specific_losses.append([\n",
    "                n_action_data, n_ships_loss, relative_position_loss, n_steps_loss, direction_loss\n",
    "            ])\n",
    "        \n",
    "        loss *= 1 / batch_size\n",
    "        \n",
    "        return (value, action_type, specific_predictions), (value_loss, type_loss, specific_losses), loss\n",
    "\n",
    "model = NNUE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T18:18:47.52493Z",
     "iopub.status.busy": "2022-06-26T18:18:47.52435Z",
     "iopub.status.idle": "2022-06-26T18:20:14.923467Z",
     "shell.execute_reply": "2022-06-26T18:20:14.92139Z",
     "shell.execute_reply.started": "2022-06-26T18:18:47.524846Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948188c9330e4f4cbd37bd955a42a171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iteration = 0\n",
    "model = model.to(device)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=h[\"lr\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=h[\"lr\"], weight_decay=0.001)\n",
    "\n",
    "if h[\"checkpoint_file\"]:\n",
    "    dict_checkpoint = torch.load(h[\"checkpoint_file\"], map_location=\"cpu\")\n",
    "    model.load_state_dict(dict_checkpoint[\"state_dict\"], strict=False)\n",
    "    if True:#not h[\"finetuning\"]:\n",
    "        optimizer.load_state_dict(dict_checkpoint[\"optimizer\"])\n",
    "        iteration = dict_checkpoint[\"iteration\"]\n",
    "        for name, value in dict_checkpoint.items():\n",
    "            if isinstance(value, int):\n",
    "                globals()[\"name\"] = value\n",
    "    del dict_checkpoint\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "train_loader_iter = iter(train_loader)\n",
    "training_stats = defaultdict(lambda: [0, 0.0])\n",
    "ACTION_NAMES = [\"spawn\", \"move\", \"attack\", \"convert\"]\n",
    "if not KAGGLE:\n",
    "    writer = SummaryWriter(STORAGE_DIR)\n",
    "t0 = time()\n",
    "\n",
    "def update_loss_stats(training_stats, value_loss, type_loss, specific_losses):\n",
    "    data_size = sum(specific_loss[0] for specific_loss in specific_losses)\n",
    "    training_stats[\"value_loss\"][0] += data_size\n",
    "    training_stats[\"value_loss\"][1] += value_loss.item()\n",
    "    training_stats[\"type_loss\"][0] += data_size\n",
    "    training_stats[\"type_loss\"][1] += type_loss.item()\n",
    "    for action_name, (n_action_data, n_ships_loss, relative_position_loss, n_steps_loss, direction_loss) in zip(ACTION_NAMES, specific_losses):\n",
    "        training_stats[f\"{action_name}_n_ships_loss\"][0] += n_action_data\n",
    "        training_stats[f\"{action_name}_n_ships_loss\"][1] += n_ships_loss.item()\n",
    "        if relative_position_loss is not None:\n",
    "            training_stats[f\"{action_name}_relative_position_loss\"][0] += n_action_data\n",
    "            training_stats[f\"{action_name}_relative_position_loss\"][1] += relative_position_loss.item()\n",
    "        if n_steps_loss is not None:\n",
    "            training_stats[f\"{action_name}_n_steps_loss\"][0] += n_action_data\n",
    "            training_stats[f\"{action_name}_n_steps_loss\"][1] += n_steps_loss.item()\n",
    "        if direction_loss is not None:\n",
    "            training_stats[f\"{action_name}_direction_loss\"][0] += n_action_data\n",
    "            training_stats[f\"{action_name}_direction_loss\"][1] += direction_loss.item()\n",
    "\n",
    "for iteration in tqdm(count(iteration)):\n",
    "    #print(iteration)\n",
    "    model.train()\n",
    "    \n",
    "    try:\n",
    "        batch = next(train_loader_iter)\n",
    "    except StopIteration:\n",
    "        train_loader_iter = iter(train_loader)\n",
    "        batch = next(train_loader_iter)\n",
    "    \n",
    "    batch = tuple(d.to(device) for d in batch)\n",
    "    optimizer.zero_grad()\n",
    "    (value, action_type, specific_predictions), (value_loss, type_loss, specific_losses), loss = model(*batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    update_loss_stats(training_stats, value_loss, type_loss, specific_losses)\n",
    "    \n",
    "    # dump stats\n",
    "    if (iteration + 1) % 1000 == 0 or iteration == 9:\n",
    "        with open(STORAGE_DIR / \"log.txt\", \"a\") as f:\n",
    "            t = round(time() - t0, 1)\n",
    "            json.dump({\n",
    "                \"time\": t,\n",
    "                \"iteration\": iteration,\n",
    "                \"stats\": training_stats,\n",
    "            }, f)\n",
    "            f.write(\"\\n\")\n",
    "        if not KAGGLE:\n",
    "            for name, stat in training_stats.items():\n",
    "                if stat[0] > 0:\n",
    "                    writer.add_scalar(\"loss/\" + name, stat[1] / stat[0], iteration + 1)\n",
    "        training_stats.clear()\n",
    "\n",
    "    # save model\n",
    "    if (iteration + 1) % 20000 == 0 or iteration == 9:\n",
    "        checkpoint_file = STORAGE_DIR / f\"checkpoint_{iteration + 1:08d}.pt\"\n",
    "        torch.save({\n",
    "            \"iteration\": iteration + 1,\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        }, checkpoint_file)\n",
    "        !cp {checkpoint_file} {STORAGE_DIR / \"latest.pt\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40k iter から value_loss の係数を 1 から 10 に変更\n",
    "# 100k iter から augmentation\n",
    "# 365k iter からデータ追加 47000 -> 60000\n",
    "# ? iter からデータ追加と negative_slope 1 / 1024\n",
    "# ? iter から AdamW\n",
    "# ? iter から lr=5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
